{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00e75aca-4e78-46cc-967c-f46fca617763",
   "metadata": {},
   "source": [
    "# Pix2Pix Architecture\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44a82085-644d-4765-b39d-954d173b54a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Computing\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Data Manipulation\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "\n",
    "# Data Visualization\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Network\n",
    "import networkx as nx\n",
    "\n",
    "# Scikit-Learn\n",
    "import sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchviz import make_dot\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e8fc04-98f8-4dad-9e59-ffd596cf7288",
   "metadata": {},
   "source": [
    "### Defining The U-Net Based Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "554b054e-cd82-4c5c-9d3b-f1461a9a9b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetGenerator(nn.Module):\n",
    "    def __init__(self, chnls_in=3, chnls_op=3):\n",
    "        super(UNetGenerator, self).__init__()\n",
    "        self.down_conv_layer_1 = DownConvBlock(chnls_in, 64, norm=False)\n",
    "        self.down_conv_layer_2 = DownConvBlock(64, 128)\n",
    "        self.down_conv_layer_3 = DownConvBlock(128, 256)\n",
    "        self.down_conv_layer_4 = DownConvBlock(256, 512, dropout=0.5)\n",
    "        self.down_conv_layer_5 = DownConvBlock(512, 512, dropout=0.5)\n",
    "        self.down_conv_layer_6 = DownConvBlock(512, 512, dropout=0.5)\n",
    "        self.down_conv_layer_7 = DownConvBlock(512, 512, dropout=0.5)\n",
    "        self.down_conv_layer_8 = DownConvBlock(512, 512, norm=False, dropout=0.5)\n",
    "        self.up_conv_layer_1 = UpConvBlock(512, 512, dropout=0.5)\n",
    "        self.up_conv_layer_2 = UpConvBlock(1024, 512, dropout=0.5)\n",
    "        self.up_conv_layer_3 = UpConvBlock(1024, 512, dropout=0.5)\n",
    "        self.up_conv_layer_4 = UpConvBlock(1024, 512, dropout=0.5)\n",
    "        self.up_conv_layer_5 = UpConvBlock(1024, 256)\n",
    "        self.up_conv_layer_6 = UpConvBlock(512, 128)\n",
    "        self.up_conv_layer_7 = UpConvBlock(256, 64)\n",
    "        self.upsample_layer = nn.Upsample(scale_factor=2)\n",
    "        self.zero_pad = nn.ZeroPad2d((1, 0, 1, 0))\n",
    "        self.conv_layer_1 = nn.Conv2d(128, chnls_op, 4, padding=1)\n",
    "        self.activation = nn.Tanh()\n",
    "    def forward(self, x):\n",
    "        enc1 = self.down_conv_layer_1(x)\n",
    "        enc2 = self.down_conv_layer_2(enc1)\n",
    "        enc3 = self.down_conv_layer_3(enc2)\n",
    "        enc4 = self.down_conv_layer_4(enc3)\n",
    "        enc5 = self.down_conv_layer_5(enc4)\n",
    "        enc6 = self.down_conv_layer_6(enc5)\n",
    "        enc7 = self.down_conv_layer_7(enc6)\n",
    "        enc8 = self.down_conv_layer_8(enc7)\n",
    "        dec1 = self.up_conv_layer_1(enc8, enc7)\n",
    "        dec2 = self.up_conv_layer_2(dec1, enc6)\n",
    "        dec3 = self.up_conv_layer_3(dec2, enc5)\n",
    "        dec4 = self.up_conv_layer_4(dec3, enc4)\n",
    "        dec5 = self.up_conv_layer_5(dec4, enc3)\n",
    "        dec6 = self.up_conv_layer_6(dec5, enc2)\n",
    "        dec7 = self.up_conv_layer_7(dec6, enc1)\n",
    "        final = self.upsample_layer(dec7)\n",
    "        final = self.zero_pad(final)\n",
    "        final = self.conv_layer_1(final)\n",
    "        return self.activation(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e11739a-bc2d-49fa-916c-6c8e64400b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpConvBlock(nn.Module):\n",
    "    def __init__(self, ip_sz, op_sz, dropout=0.0):\n",
    "        super(UpConvBlock, self).__init__()\n",
    "        self.layers = [\n",
    "            nn.ConvTranspose2d(ip_sz, op_sz, 4, 2, 1),\n",
    "            nn.InstanceNorm2d(op_sz),\n",
    "            nn.ReLU(),\n",
    "        ]\n",
    "        if dropout:\n",
    "            self.layers += [nn.Dropout(dropout)]\n",
    "    def forward(self, x, enc_ip):\n",
    "        x = nn.Sequential(*(self.layers))(x)\n",
    "        op = torch.cat((x, enc_ip), 1)\n",
    "        return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a358f887-67d1-42ab-b5a5-1e62740251df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownConvBlock(nn.Module):\n",
    "    def __init__(self, ip_sz, op_sz, norm=True, dropout=0.0):\n",
    "        super(DownConvBlock, self).__init__()\n",
    "        self.layers = [nn.Conv2d(ip_sz, op_sz, 4, 2, 1)]\n",
    "        if norm:\n",
    "            self.layers.append(nn.InstanceNorm2d(op_sz))\n",
    "        self.layers += [nn.LeakyReLU(0.2)]\n",
    "        if dropout:\n",
    "            self.layers += [nn.Dropout(dropout)]\n",
    "    def forward(self, x):\n",
    "        op = nn.Sequential(*(self.layers))(x)\n",
    "        return op"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5c184d-03d8-4828-b36f-fb8046631c69",
   "metadata": {},
   "source": [
    "### Defining The Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfe63aad-274c-4e46-b8a3-281900c5830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pix2PixDiscriminator(nn.Module):\n",
    "    def __init__(self, chnls_in=3):\n",
    "        super(Pix2PixDiscriminator, self).__init__()\n",
    "        def disc_conv_block(chnls_in, chnls_op, norm=1):\n",
    "            layers = [nn.Conv2d(chnls_in, chnls_op, 4, stride=2, padding=1)]\n",
    "            if normalization:\n",
    "                layers.append(nn.InstanceNorm2d(chnls_op))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "        self.lyr1 = disc_conv_block(chnls_in * 2, 64, norm=0)\n",
    "        self.lyr2 = disc_conv_block(64, 128)\n",
    "        self.lyr3 = disc_conv_block(128, 256)\n",
    "        self.lyr4 = disc_conv_block(256, 512)\n",
    "    def forward(self, real_image, translated_image):\n",
    "        ip = torch.cat((real_image, translated_image), 1)\n",
    "        op = self.lyr1(ip)\n",
    "        op = self.lyr2(op)\n",
    "        op = self.lyr3(op)\n",
    "        op = self.lyr4(op)\n",
    "        op = nn.ZeroPad2d((1, 0, 1, 0))(op)\n",
    "        op = nn.Conv2d(512, 1, 4, padding=1)(op)\n",
    "        return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579666a8-0101-4c7b-9f2b-9ff63b6d8b34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
