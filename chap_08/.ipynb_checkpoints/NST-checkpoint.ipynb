{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83d12082-6afc-45e2-9fd5-b0a77f4ca980",
   "metadata": {},
   "source": [
    "# Neural Style Transfer\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec3e2d6e-24f3-4ca4-9e99-6dd86e661ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Computing\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Data Manipulation\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "\n",
    "# Data Visualization\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Network\n",
    "import networkx as nx\n",
    "\n",
    "# Scikit-Learn\n",
    "import sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchviz import make_dot\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb86aa43-7e37-4738-87ab-f5979d62c63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvc = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969a9340-aa24-4b62-84fc-72fdc10c6fe5",
   "metadata": {},
   "source": [
    "### Image to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d403dca-dd27-4056-acfe-e584814c2857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_tensor(image_filepath, image_dimension=128):\n",
    "    img = Image.open(image_filepath).convert('RGB')\n",
    "    \n",
    "    # display image to check \n",
    "    plt.figure()\n",
    "    plt.title(image_filepath)\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    if max(img.size) <= image_dimension:\n",
    "        img_size = max(img.size)\n",
    "    else:\n",
    "        img_size = image_dimension\n",
    "  \n",
    "    torch_transformation = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize(img_size),\n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])\n",
    "  \n",
    "    img = torch_transformation(img).unsqueeze(0)\n",
    "  \n",
    "    return img.to(dvc, torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d57fb07-903c-4715-913e-2e940700c15a",
   "metadata": {},
   "source": [
    "### Defining `Gram Matrix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541a28cb-bd50-48cb-984b-c1976daee615",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
