{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f23fc57-5a2e-4b90-b5f9-276c42d61ae6",
   "metadata": {},
   "source": [
    "# Long-Short Term Memory\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fda69f02-ea7b-4d0f-be04-95749df93d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operating Systems\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "\n",
    "# Notebook Performance\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Numerical Computing\n",
    "import numpy as np\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# from torchtext.legacy import data\n",
    "from torch.optim import lr_scheduler\n",
    "# from torchtext.legacy import datasets\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Tokenization\n",
    "import nltk\n",
    "import pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de8b76c8-a998-4ac3-91f8-5ce00ddd8f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b28bda9-a031-4a85-a3a2-2b9b66f8fa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487be56b-c7ba-4a49-ba1f-1449ad17160d",
   "metadata": {},
   "source": [
    "#### Placing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5a9a95d-86b1-4a28-a53f-452271440f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_FIELD = data.Field(tokenize = data.get_tokenizer(\"basic_english\"), include_lengths = True)\n",
    "\n",
    "LABEL_FIELD = data.LabelField(dtype = torch.float)\n",
    "\n",
    "# Train, Validation & Test Sets\n",
    "train_dataset, test_dataset = datasets.IMDB.splits(TEXT_FIELD, LABEL_FIELD)\n",
    "\n",
    "train_dataset, valid_dataset = train_dataset.split(random_state = random.seed(123))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7db26592-082a-4de1-a2bf-4d87e6c1b072",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCABULARY_SIZE = 25000\n",
    "\n",
    "TEXT_FIELD.build_vocab(train_dataset, max_size = MAX_VOCABULARY_SIZE)\n",
    "\n",
    "LABEL_FIELD.build_vocab(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "862158fa-67bb-4f2b-aef2-0a90e3be213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_data_iterator, valid_data_iterator, test_data_iterator = data.BucketIterator.splits(\n",
    "    (train_dataset, valid_dataset, test_dataset), \n",
    "    batch_size = B_SIZE,\n",
    "    sort_within_batch = True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2930ed16-e9fd-463b-8342-1303dabd7319",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, PackedSequence\n",
    "\n",
    "def cuda_pack_padded_sequence(input, lengths, batch_first=False, enforce_sorted=True):\n",
    "    lengths = torch.as_tensor(lengths, dtype=torch.int64)\n",
    "    lengths = lengths.cpu()\n",
    "    if enforce_sorted:\n",
    "        sorted_indices = None\n",
    "    else:\n",
    "        lengths, sorted_indices = torch.sort(lengths, descending=True)\n",
    "        sorted_indices = sorted_indices.to(input.device)\n",
    "    batch_dim = 0 if batch_first else 1\n",
    "    input = input.index_select(batch_dim, sorted_indices)\n",
    "\n",
    "    data, batch_sizes = \\\n",
    "    torch._C._VariableFunctions._pack_padded_sequence(input, lengths, batch_first)\n",
    "    return PackedSequence(data, batch_sizes, sorted_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "782b8490-43e0-4f08-a04a-933fe62129f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocabulary_size, embedding_dimension, hidden_dimension, output_dimension, dropout, pad_index):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = nn.Embedding(vocabulary_size, embedding_dimension, padding_idx = pad_index)\n",
    "        self.lstm_layer = nn.LSTM(embedding_dimension, \n",
    "                           hidden_dimension, \n",
    "                           num_layers=1, \n",
    "                           bidirectional=True, \n",
    "                           dropout=dropout)\n",
    "        self.fc_layer = nn.Linear(hidden_dimension * 2, output_dimension)\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, sequence, sequence_lengths=None):\n",
    "        if sequence_lengths is None:\n",
    "            sequence_lengths = torch.LongTensor([len(sequence)])\n",
    "        \n",
    "        # sequence := (sequence_length, batch_size)\n",
    "        embedded_output = self.dropout_layer(self.embedding_layer(sequence))\n",
    "        \n",
    "        \n",
    "        # embedded_output := (sequence_length, batch_size, embedding_dimension)\n",
    "        if torch.cuda.is_available():\n",
    "            packed_embedded_output = cuda_pack_padded_sequence(embedded_output, sequence_lengths)\n",
    "        else:\n",
    "            packed_embedded_output = nn.utils.rnn.pack_padded_sequence(embedded_output, sequence_lengths)\n",
    "        \n",
    "        packed_output, (hidden_state, cell_state) = self.lstm_layer(packed_embedded_output)\n",
    "        # hidden_state := (num_layers * num_directions, batch_size, hidden_dimension)\n",
    "        # cell_state := (num_layers * num_directions, batch_size, hidden_dimension)\n",
    "        \n",
    "        op, op_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "        # op := (sequence_length, batch_size, hidden_dimension * num_directions)\n",
    "        \n",
    "        hidden_output = torch.cat((hidden_state[-2,:,:], hidden_state[-1,:,:]), dim = 1)        \n",
    "        # hidden_output := (batch_size, hidden_dimension * num_directions)\n",
    "        \n",
    "        return self.fc_layer(hidden_output)\n",
    "\n",
    "    \n",
    "INPUT_DIMENSION = len(TEXT_FIELD.vocab)\n",
    "\n",
    "EMBEDDING_DIMENSION = 100\n",
    "\n",
    "HIDDEN_DIMENSION = 32\n",
    "\n",
    "OUTPUT_DIMENSION = 1\n",
    "\n",
    "DROPOUT = 0.5\n",
    "\n",
    "PAD_INDEX = TEXT_FIELD.vocab.stoi[TEXT_FIELD.pad_token]\n",
    "\n",
    "lstm_model = LSTM(INPUT_DIMENSION, \n",
    "            EMBEDDING_DIMENSION, \n",
    "            HIDDEN_DIMENSION, \n",
    "            OUTPUT_DIMENSION, \n",
    "            DROPOUT, \n",
    "            PAD_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88f0eabd-446e-4608-8d9f-d5d11cf04532",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_INDEX = TEXT_FIELD.vocab.stoi[TEXT_FIELD.unk_token]\n",
    "\n",
    "lstm_model.embedding_layer.weight.data[UNK_INDEX] = torch.zeros(EMBEDDING_DIMENSION)\n",
    "lstm_model.embedding_layer.weight.data[PAD_INDEX] = torch.zeros(EMBEDDING_DIMENSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20719df3-c0b3-4310-a9ca-3bb35b407e6f",
   "metadata": {},
   "source": [
    "#### Optimization Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fa1f6ca-43a0-4007-b166-fb5f2935d368",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(lstm_model.parameters())\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "\n",
    "lstm_model = lstm_model.to(device)\n",
    "loss_func = loss_func.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42405c5-49ee-4333-aebf-9b9a7a0d8c5e",
   "metadata": {},
   "source": [
    "#### Placing `Accuracy Metric` Function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1e1f238-2fce-4be6-9ae9-cc7db1336615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metric(predictions, ground_truth):\n",
    "    \"\"\"\n",
    "    Returns 0-1 accuracy for the given set of predictions and ground truth\n",
    "    \"\"\"\n",
    "    rounded_predictions = torch.round(torch.sigmoid(predictions))\n",
    "    success = (rounded_predictions == ground_truth).float() #convert into float for division \n",
    "    accuracy = success.sum() / len(success)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554d9c71-4d6d-47da-a7c8-02ea6f9ce64c",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc421ec1-5d63-4fa7-9bd6-a24841549fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_iterator, optim, loss_func):\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    model.train()\n",
    "    \n",
    "    for curr_batch in data_iterator:\n",
    "        optim.zero_grad()\n",
    "        sequence, sequence_lengths = curr_batch.text\n",
    "        preds = lstm_model(sequence, sequence_lengths).squeeze(1)\n",
    "        \n",
    "        loss_curr = loss_func(preds, curr_batch.label)\n",
    "        accuracy_curr = accuracy_metric(preds, curr_batch.label)\n",
    "        \n",
    "        loss_curr.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        loss += loss_curr.item()\n",
    "        accuracy += accuracy_curr.item()\n",
    "        \n",
    "    return loss/len(data_iterator), accuracy/len(data_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0d8bd9-985a-4548-97af-e8c0b00f472c",
   "metadata": {},
   "source": [
    "### Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b277184e-ab4e-4a0a-ba36-a423f4b1bf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, data_iterator, loss_func):\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for curr_batch in data_iterator:\n",
    "            sequence, sequence_lengths = curr_batch.text\n",
    "            preds = model(sequence, sequence_lengths).squeeze(1)\n",
    "            \n",
    "            loss_curr = loss_func(preds, curr_batch.label)\n",
    "            accuracy_curr = accuracy_metric(preds, curr_batch.label)\n",
    "\n",
    "            loss += loss_curr.item()\n",
    "            accuracy += accuracy_curr.item()\n",
    "        \n",
    "    return loss/len(data_iterator), accuracy/len(data_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55f552af-87a9-4d39-9e30-2676852e00fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "best_validation_loss = float('inf')\n",
    "\n",
    "for ep in range(num_epochs):\n",
    "\n",
    "    time_start = time.time()\n",
    "    \n",
    "    training_loss, train_accuracy = train(lstm_model, train_data_iterator, optim, loss_func)\n",
    "    validation_loss, validation_accuracy = validate(lstm_model, valid_data_iterator, loss_func)\n",
    "    \n",
    "    time_end = time.time()\n",
    "    time_delta = time_end - time_start \n",
    "    \n",
    "    if validation_loss < best_validation_loss:\n",
    "        best_validation_loss = validation_loss\n",
    "        torch.save(lstm_model.state_dict(), 'lstm_model.pt')\n",
    "    \n",
    "    print(f'epoch number: {ep+1} | time elapsed: {time_delta}s')\n",
    "    print(f'training loss: {training_loss:.3f} | training accuracy: {train_accuracy*100:.2f}%')\n",
    "    print(f'validation loss: {validation_loss:.3f} |  validation accuracy: {validation_accuracy*100:.2f}%')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4ab407-457a-42d1-bca8-2580f424a161",
   "metadata": {},
   "source": [
    "### Model Outcome:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b77083e-f686-4598-800e-f65e01963023",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.load_state_dict(torch.load('./lstm_model.pt'))\n",
    "\n",
    "test_loss, test_accuracy = validate(lstm_model, test_data_iterator, loss_func)\n",
    "\n",
    "print(f'test loss: {test_loss:.3f} | test accuracy: {test_accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476fff52-4983-47da-a0cf-47207d849db4",
   "metadata": {},
   "source": [
    "### Sentiment Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3481e29-1709-4416-876d-294138f3c686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_inference(model, sentence):\n",
    "    model.eval()\n",
    "    \n",
    "    # text transformations\n",
    "    tokenized = data.get_tokenizer(\"basic_english\")(sentence)\n",
    "    tokenized = [TEXT_FIELD.vocab.stoi[t] for t in tokenized]\n",
    "    \n",
    "    # model inference\n",
    "    model_input = torch.LongTensor(tokenized).to(device)\n",
    "    model_input = model_input.unsqueeze(1)\n",
    "    \n",
    "    pred = torch.sigmoid(model(model_input))\n",
    "    \n",
    "    return pred.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a19b9b84-5c2c-4cb0-aef1-e6fc0e95a056",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentiment_inference(lstm_model, \"This film is horrible\"))\n",
    "\n",
    "print(sentiment_inference(lstm_model, \"Director tried too hard but this film is bad\"))\n",
    "\n",
    "print(sentiment_inference(lstm_model, \"This film will be houseful for weeks\"))\n",
    "\n",
    "print(sentiment_inference(lstm_model, \"I just really loved the movie\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e0c403-58dd-4d8c-93fc-f0fe2c4ea9ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
