{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c69036c4-c974-437c-9990-b880b4743b72",
   "metadata": {},
   "source": [
    "# Deep Recurrent Model Architecture\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46d4971b-d245-499a-833d-34cbb2a4ffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operating Systems\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "\n",
    "# Notebook Performance\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Numerical Computing\n",
    "import numpy as np\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Tokenization\n",
    "import nltk\n",
    "import pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c07a5787-007c-4fee-b8fe-c9f87f3cd873",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78469530-330a-40f4-8d99-a6960c0e8dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a8d3fa-5b6b-48c3-9e4f-59bf438d1f1e",
   "metadata": {},
   "source": [
    "### Dataset Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58290761-15a5-4fc2-88b1-26fe21f5887e",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_list = []\n",
    "label_list = []\n",
    "for label in ['pos', 'neg']:\n",
    "    for fname in tqdm(os.listdir(f'./aclImdb/train/{label}/')):\n",
    "        if 'txt' not in fname:\n",
    "            continue\n",
    "        with open(os.path.join(f'./aclImdb/train/{label}/', fname), encoding=\"utf8\") as f:\n",
    "            review_list += [f.read()]\n",
    "            label_list += [label]\n",
    "print ('Number of reviews :', len(review_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba7998e-a46b-491b-99ec-1d6ea4e09872",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c1f5acc-d004-470d-bef3-67b126699894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Pre-Processing \n",
    "review_list = [review.lower() for review in review_list]\n",
    "review_list = [''.join([letter for letter in review if letter not in punctuation]) for review in tqdm(review_list)]\n",
    "\n",
    "reviews_blob = ' '.join(review_list)\n",
    "\n",
    "review_words = reviews_blob.split()\n",
    "\n",
    "count_words = Counter(review_words)\n",
    "\n",
    "# Sorting\n",
    "total_review_words = len(review_words)\n",
    "sorted_review_words = count_words.most_common(total_review_words)\n",
    "\n",
    "print(sorted_review_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81a11179-0e01-4d0f-8947-c33ef48915a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_to_token = {word:idx+1 for idx, (word, count) in enumerate(sorted_review_words)}\n",
    "print(list(vocab_to_token.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "369b926e-7b52-4b1b-8b25-c82df08b67be",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_tokenized = []\n",
    "\n",
    "for review in review_list:\n",
    "    word_to_token = [vocab_to_token[word] for word in review.split()]\n",
    "    reviews_tokenized.append(word_to_token)\n",
    "\n",
    "print(review_list[0])\n",
    "print()\n",
    "print (reviews_tokenized[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17ad37c-2862-44e0-bbd1-37167b489b2b",
   "metadata": {},
   "source": [
    "### Binary Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f2673a9-5402-467e-b961-8a07a823cbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment's Encoding as [0 or 1]\n",
    "encoded_label_list = [1 if label =='pos' else 0 for label in label_list]\n",
    "\n",
    "reviews_len = [len(review) for review in reviews_tokenized]\n",
    "\n",
    "reviews_tokenized = [reviews_tokenized[i] for i, l in enumerate(reviews_len) if l>0 ]\n",
    "encoded_label_list = np.array([encoded_label_list[i] for i, l in enumerate(reviews_len) if l> 0 ], dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dfa3a7-94fd-4b3f-aea2-b0f38499289d",
   "metadata": {},
   "source": [
    "### `Pad Sequence` Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3db5aac1-3bd3-4522-a809-eca2f795adfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(reviews_tokenized, sequence_length):\n",
    "    ''' returns the tokenized review sequences padded with 0's or truncated to the sequence_length.\n",
    "    '''\n",
    "    padded_reviews = np.zeros((len(reviews_tokenized), sequence_length), dtype = int)\n",
    "    \n",
    "    for idx, review in enumerate(reviews_tokenized):\n",
    "        review_len = len(review)\n",
    "        \n",
    "        if review_len <= sequence_length:\n",
    "            zeroes = list(np.zeros(sequence_length-review_len))\n",
    "            new_sequence = zeroes+review\n",
    "        elif review_len > sequence_length:\n",
    "            new_sequence = review[0:sequence_length]\n",
    "        \n",
    "        padded_reviews[idx,:] = np.array(new_sequence)\n",
    "    \n",
    "    return padded_reviews\n",
    "\n",
    "sequence_length = 512\n",
    "padded_reviews = pad_sequence(reviews_tokenized=reviews_tokenized, sequence_length=sequence_length)\n",
    "\n",
    "plt.hist(reviews_len);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35b767c2-d94c-4571-bb5c-ba4511eff494",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_split = 0.75\n",
    "\n",
    "train_X = padded_reviews[:int(train_val_split*len(padded_reviews))]\n",
    "train_y = encoded_label_list[:int(train_val_split*len(padded_reviews))]\n",
    "\n",
    "validation_X = padded_reviews[int(train_val_split*len(padded_reviews)):]\n",
    "validation_y = encoded_label_list[int(train_val_split*len(padded_reviews)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69a20db6-c26e-47b7-9708-93e8b0459fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.astype('int64')\n",
    "train_y = train_y.astype('int64')\n",
    "\n",
    "validation_X = validation_X.astype('int64')\n",
    "validation_y = validation_y.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0df08b25-99ea-49bf-b18d-be33ef38994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Torch Datasets\n",
    "train_dataset = TensorDataset(torch.from_numpy(train_X).to(device), torch.from_numpy(train_y).to(device))\n",
    "validation_dataset = TensorDataset(torch.from_numpy(validation_X).to(device), torch.from_numpy(validation_y).to(device))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Torch DataLoaders (Shuffling Data)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b8f2b12-c0d6-409a-8649-60b3e03a6321",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_iter = iter(train_dataloader)\n",
    "X_example, y_example = next(train_data_iter)\n",
    "\n",
    "print('Example Input size: ', X_example.size()) # batch_size, seq_length\n",
    "print('Example Input:\\n', X_example)\n",
    "\n",
    "print()\n",
    "\n",
    "print('Example Output size: ', y_example.size()) # batch_size\n",
    "print('Example Output:\\n', y_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3663b835-3d98-4b7a-8b13-1e3e9c175a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dimension, embedding_dimension, hidden_dimension, output_dimension):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = nn.Embedding(input_dimension, embedding_dimension)  \n",
    "        self.rnn_layer = nn.RNN(embedding_dimension, hidden_dimension, num_layers=1)\n",
    "        self.fc_layer = nn.Linear(hidden_dimension, output_dimension)\n",
    "        \n",
    "    def forward(self, sequence):\n",
    "        # sequence shape = (sequence_length, batch_size)\n",
    "        embedding = self.embedding_layer(sequence)  \n",
    "        # embedding shape = [sequence_length, batch_size, embedding_dimension]\n",
    "        output, hidden_state = self.rnn_layer(embedding)\n",
    "        # output shape = [sequence_length, batch_size, hidden_dimension]\n",
    "        # hidden_state shape = [1, batch_size, hidden_dimension]\n",
    "        final_output = self.fc_layer(hidden_state[-1,:,:].squeeze(0))      \n",
    "        return final_output\n",
    "    \n",
    "input_dimension = len(vocab_to_token)+1 \n",
    "\n",
    "embedding_dimension = 100\n",
    "\n",
    "hidden_dimension = 32\n",
    "\n",
    "output_dimension = 1\n",
    "\n",
    "rnn_model = RNN(input_dimension, embedding_dimension, hidden_dimension, output_dimension)\n",
    "\n",
    "optim = torch.optim.Adam(rnn_model.parameters())\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "\n",
    "rnn_model = rnn_model.to(device)\n",
    "loss_func = loss_func.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4052cde6-c48f-46f7-a440-f00c94f046e9",
   "metadata": {},
   "source": [
    "### Placing `Accuracy Metric`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19df4428-5545-4c26-98c7-cf684d70d9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metric(predictions, ground_truth):\n",
    "    \"\"\"\n",
    "    Returns 0-1 accuracy for the given set of predictions and ground truth\n",
    "    \"\"\"\n",
    "    rounded_predictions = torch.round(torch.sigmoid(predictions))\n",
    "    success = (rounded_predictions == ground_truth).float() #convert into float for division \n",
    "    accuracy = success.sum() / len(success)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6280eb4c-d1b0-4e25-8b62-fca7e753acaf",
   "metadata": {},
   "source": [
    "### `Model Training`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24ae6062-2326-442a-94dd-340cf45a0256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optim, loss_func):\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    model.train()\n",
    "    \n",
    "    for sequence, sentiment in dataloader:\n",
    "        optim.zero_grad()     \n",
    "        preds = model(sequence.T).squeeze()\n",
    "        \n",
    "        loss_curr = loss_func(preds, sentiment)\n",
    "        accuracy_curr = accuracy_metric(preds, sentiment)\n",
    "        \n",
    "        loss_curr.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        loss += loss_curr.item()\n",
    "        accuracy += accuracy_curr.item()\n",
    "        \n",
    "    return loss/len(dataloader), accuracy/len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93e3332-6fa9-444b-a941-23e1571fbcc1",
   "metadata": {},
   "source": [
    "### `Validation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e96440b8-4058-4e85-94e5-3acbedd50676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, loss_func):\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sequence, sentiment in dataloader:\n",
    "            \n",
    "            preds = model(sequence.T).squeeze()\n",
    "            \n",
    "            loss_curr = loss_func(preds, sentiment)   \n",
    "            accuracy_curr = accuracy_metric(preds, sentiment)\n",
    "\n",
    "            loss += loss_curr.item()\n",
    "            accuracy += accuracy_curr.item()\n",
    "        \n",
    "    return loss/len(dataloader), accuracy/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7de13399-49a6-4bd3-9c6a-bbcfa508d6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "best_validation_loss = float('inf')\n",
    "\n",
    "for ep in range(num_epochs):\n",
    "\n",
    "    time_start = time.time()\n",
    "    \n",
    "    training_loss, train_accuracy = train(rnn_model, train_dataloader, optim, loss_func)\n",
    "    validation_loss, validation_accuracy = validate(rnn_model, validation_dataloader, loss_func)\n",
    "    \n",
    "    time_end = time.time()\n",
    "    time_delta = time_end - time_start  \n",
    "    \n",
    "    if validation_loss < best_validation_loss:\n",
    "        best_validation_loss = validation_loss\n",
    "        torch.save(rnn_model.state_dict(), 'rnn_model.pt')\n",
    "    \n",
    "    print(f'epoch number: {ep+1} | time elapsed: {time_delta}s')\n",
    "    print(f'training loss: {training_loss:.3f} | training accuracy: {train_accuracy*100:.2f}%')\n",
    "    print(f'validation loss: {validation_loss:.3f} |  validation accuracy: {validation_accuracy*100:.2f}%')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed31806-0fec-47e8-b62e-913970cd19ad",
   "metadata": {},
   "source": [
    "### `Sentiment Inference`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa15bd47-c43b-4f1c-860b-5325899a3428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_inference(model, sentence):\n",
    "    model.eval()\n",
    "    \n",
    "    # Text Transformations\n",
    "    sentence = sentence.lower()\n",
    "    sentence = ''.join([c for c in sentence if c not in punctuation])\n",
    "    tokenized = [vocab_to_token.get(token, 0) for token in sentence.split()]\n",
    "    tokenized = np.pad(tokenized, (512-len(tokenized), 0), 'constant')\n",
    "    \n",
    "    # Model Inference\n",
    "    model_input = torch.LongTensor(tokenized).to(device)\n",
    "    model_input = model_input.unsqueeze(1)\n",
    "    pred = torch.sigmoid(model(model_input))\n",
    "    \n",
    "    return pred.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22b5ad95-1365-4832-af79-fb6a8b2ea08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentiment_inference(rnn_model, \"This film is horrible\"))\n",
    "\n",
    "print(sentiment_inference(rnn_model, \"Director tried too hard but this film is bad\"))\n",
    "\n",
    "print(sentiment_inference(rnn_model, \"This film will be houseful for weeks\"))\n",
    "\n",
    "print(sentiment_inference(rnn_model, \"I just really loved the movie\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
